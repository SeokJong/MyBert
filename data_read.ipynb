{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"MAX_SEQ_LENGTH\": 128,\n",
    "    \"MASKED_LM_PROB\": 0.15,\n",
    "    \"MAX_PREDICTIONS\": 20,\n",
    "    \"DO_LOWER_CASE\": True,\n",
    "    \"PROCESSES\": 2,\n",
    "    \"INPUT_DIR\": \"shards\",\n",
    "    \"PRETRAINING_DIR\": \"pretraining_data\",\n",
    "    \"DUPE_FACTOR\": 5,\n",
    "    \"SHORT_SEQ_PROB\": 0.1,\n",
    "    \"BATCH_SIZE\" : 32,\n",
    "    \"VOCAB_SIZE\" : 32000,\n",
    "    \"VOCAB_TOKEN\" : 2,\n",
    "    \"HIDDEN_SIZE\" : 128,\n",
    "    \"MAX_POS_EMBED\" : 128,\n",
    "    \"NORM_EPS\" : 0.001,\n",
    "    \"DROPOUT_RATE\" : 0.1,\n",
    "    \"INIT_RANGE\" : 0.02,\n",
    "    \"ATT_HEAD\" : 2,\n",
    "    \"ATT_HEAD_SIZE\" : 0.02,\n",
    "    \"INIT_RANGE\" : 0.02,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"base_model.json\", \"w\") as fout:\n",
    "    json.dump(options, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(input_files,\n",
    "                     max_seq_length,\n",
    "                     max_predictions_per_seq,\n",
    "                     is_training,\n",
    "                     num_cpu_threads=4):\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    batch_size = params[\"BATCH_SIZE\"]\n",
    "\n",
    "    name_to_features = {\n",
    "        \"input_ids\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"input_mask\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"segment_ids\":\n",
    "            tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "        \"masked_lm_positions\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "        \"masked_lm_ids\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "        \"masked_lm_weights\":\n",
    "            tf.io.FixedLenFeature([max_predictions_per_seq], tf.float32),\n",
    "        \"next_sentence_labels\":\n",
    "            tf.io.FixedLenFeature([1], tf.int64),\n",
    "    }\n",
    "\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "    if is_training:\n",
    "      d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=len(input_files))\n",
    "      # `cycle_length` is the number of parallel files that get read.\n",
    "      cycle_length = min(num_cpu_threads, len(input_files))\n",
    "      d = d.interleave(\n",
    "              tf.data.TFRecordDataset,\n",
    "              cycle_length=cycle_length\n",
    "      )\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "    else:\n",
    "      d = tf.data.TFRecordDataset(input_files)\n",
    "      # Since we evaluate for a fixed number of steps we don't want to encounter\n",
    "      # out-of-range exceptions.\n",
    "      d = d.repeat()\n",
    "\n",
    "    # We must `drop_remainder` on training because the TPU requires fixed\n",
    "    # size dimensions. For eval, we assume we are evaluating on the CPU or GPU\n",
    "    # and we *don't* want to drop the remainder, otherwise we wont cover\n",
    "    # every sample.\n",
    "    d = d.map(lambda record: _decode_record(record, name_to_features),\n",
    "            num_parallel_calls=num_cpu_threads)\n",
    "    d = d.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    return d\n",
    "\n",
    "  return input_fn\n",
    "\n",
    "\n",
    "def _decode_record(record, name_to_features):\n",
    "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "  example = tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "  # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "  # So cast all int64 to int32.\n",
    "  for name in list(example.keys()):\n",
    "    t = example[name]\n",
    "    if t.dtype == tf.int64:\n",
    "      t = tf.cast(t, tf.int32)\n",
    "    example[name] = t\n",
    "\n",
    "  return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pattern = f\"./{options['PRETRAINING_DIR']}/*\"\n",
    "input_files = []\n",
    "input_files.extend(tf.io.gfile.glob(data_pattern))\n",
    "builder = input_fn_builder(input_files, 128, 20, True, 4)\n",
    "params = options\n",
    "data = builder(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    d = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       " array([[    2,    26,    11, ..., 19171,  3224,     3],\n",
       "        [    2,  1032,  1670, ...,     0,     0,     0],\n",
       "        [    2,    11,     4, ...,     4,  1838,     3],\n",
       "        ...,\n",
       "        [    2,    45,    20, ...,     0,     0,     0],\n",
       "        [    2,    65,   546, ...,     0,     0,     0],\n",
       "        [    2,    28,   693, ...,     0,     0,     0]])>,\n",
       " 'input_mask': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " 'masked_lm_ids': <tf.Tensor: shape=(32, 20), dtype=int32, numpy=\n",
       " array([[   12,     5,  2459,   103,   250,   218, 17135,    12,  1553,\n",
       "            12,   103,   517,  3492,  2620,   983, 12622,    53,    16,\n",
       "             7,     0],\n",
       "        [  100,   783,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    8,   460,    27, 12227,    60,   235,   254,    43,  5737,\n",
       "            57,  1310,     8,    36,    35,  6533,    10,    67,    38,\n",
       "             5,     0],\n",
       "        [   85,    60,    95,    12,    52,  1150,  1150,  2610,  7654,\n",
       "          1287,    16,  1495,   103,   253,    19,     7,     8,    12,\n",
       "          4995,     0],\n",
       "        [   20,    31,    44,    26,    11,  4409,    76,    81,    32,\n",
       "             9,   487,    17,    21,  1875,    54,    26,     7,  1703,\n",
       "          8558,     0],\n",
       "        [ 1109,     6,     1,   194,   512,    10,    89,  2776,   123,\n",
       "            25,  2541,   816,   107,  7590,    26,   241,     7,   513,\n",
       "            28,     0],\n",
       "        [   22,   523,    40,   242,   762,  5259,    85,    85,  8525,\n",
       "             5,    48,     5,   565,    12,   600,    96,     0,     0,\n",
       "             0,     0],\n",
       "        [  153,    37,   137,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    6,    39,    10,   227,   157,   643,   227,   105,    11,\n",
       "             8,    15,   115,    40,  9789,    12,    11,     8,  4536,\n",
       "          1035,     0],\n",
       "        [   50,    26,    53,    18,     6,    30,     5,    15,    10,\n",
       "             6,   146,   112,    13,   151,    48,    32,   139,  6833,\n",
       "           864,     0],\n",
       "        [  275,    14,   232,  1262,  1155,    12,    15,   387,  1641,\n",
       "          1172,  4199,    12,  2547,   315,   404,   712,   162,     9,\n",
       "            19,     0],\n",
       "        [  124,     6,   206,    43,    43,   203,     7, 14809,     8,\n",
       "           394,   537,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [   15,    36,    28,  3052,     5,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    9,    18,    37,  1151,    16, 13578,   230,   230,  7023,\n",
       "          1196,    12,    44,  5069,  7049,     6,    66,   144,    71,\n",
       "            10,     0],\n",
       "        [  475,    65,   230,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [ 2077,    10,  1225,   365,    95,    53,   194,    19, 14394,\n",
       "             8,   161,    59,   390,  2645,    59,    98,    61,    93,\n",
       "           245,     0],\n",
       "        [   76,    13,   401,  1779,    11,    40,    46,    34,   154,\n",
       "            40,  3329,    15,  1779,   521,   154,    10,   167,  1779,\n",
       "          1779,     0],\n",
       "        [ 1747,   204,   247,   401,    56,    19,  1183,  4969,   205,\n",
       "            15,   201,   276,  3563,    53,    14,   188,     0,     0,\n",
       "             0,     0],\n",
       "        [ 7820,    15,    16, 11072,  6036,   132,    37,  4621,    42,\n",
       "           126,     8,  7727,   734,   400,  6267,   247,    71,  2224,\n",
       "            74,     0],\n",
       "        [   17,    50,    53,    11,    20,     7,    94,    35,  2690,\n",
       "             5,    38,   381,   299,   211,   354,    51,    25,    12,\n",
       "           446,     0],\n",
       "        [   15,    19, 13265,   104,    52,  4609,   524,    99,    31,\n",
       "            20,  1470,   124,  1702,    15,    60,     6,    47,   266,\n",
       "          3505,     0],\n",
       "        [    6,    10,   383,    24,  8713,    71,    14,   394,  1571,\n",
       "           120,    19,   273,     9,     7, 11349,    12,   110,     6,\n",
       "             5,     0],\n",
       "        [   51,    72,    21,    44,   155,   243,   219,    37,  1566,\n",
       "           124,    99,    74,    32,    19,   174,     9,   129,    56,\n",
       "            50,     0],\n",
       "        [   20,    12,   593,   906,   111,   538,    72,     9,    18,\n",
       "             8,   746,    28,   527,   148,    45,    64,  3437,    12,\n",
       "          4263,     0],\n",
       "        [   32,    18,   331,     7,    34,    49,  2387,    45,    15,\n",
       "          9754,     9,     9,    24,    40,    59,    48,    50,    14,\n",
       "           503,     0],\n",
       "        [   10,  2038,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    6,    72,   145,   900,   308,    10,    40,    55,    19,\n",
       "           900,   182,    15,    31,    59,   127,     9,     9,   900,\n",
       "             0,     0],\n",
       "        [   14,   195,   132,     9,    17,    59,    38,    36,    20,\n",
       "           247,  1222,     6,     8,   292,   112,    32,    13,    52,\n",
       "            25,     0],\n",
       "        [  252,    46,    97,   367,  2047,  3916,    82,    18,     7,\n",
       "            71,    86,    71,  4348,    23,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [16201, 15859,   388,   723,    20,   172,  1099,   518,   113,\n",
       "          1565, 11131,   545,    14,   212,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    7,  2089,    16,  3289, 13558,    12,    33,     9,   153,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [   37,    12,     7,  5203,    35,    18,  8634,   794,     7,\n",
       "           366,     5,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])>,\n",
       " 'masked_lm_positions': <tf.Tensor: shape=(32, 20), dtype=int32, numpy=\n",
       " array([[  6,   8,  13,  19,  21,  27,  32,  38,  40,  71,  75,  81,  88,\n",
       "          93, 103, 107, 109, 120, 123,   0],\n",
       "        [  8,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [  2,   4,  10,  13,  16,  35,  45,  52,  58,  63,  71,  79,  81,\n",
       "          83,  86,  98, 102, 105, 125,   0],\n",
       "        [ 11,  19,  25,  29,  48,  54,  57,  60,  65,  69,  80,  84,  90,\n",
       "          97, 105, 111, 113, 116, 118,   0],\n",
       "        [  3,   4,   5,   7,   9,  16,  21,  25,  50,  53,  56,  64,  65,\n",
       "          69,  76,  83, 105, 121, 125,   0],\n",
       "        [  6,   9,  12,  14,  18,  23,  25,  26,  40,  46,  65,  72,  88,\n",
       "         109, 115, 117, 122, 123, 125,   0],\n",
       "        [  2,  10,  20,  24,  25,  36,  37,  44,  46,  48,  56,  57,  65,\n",
       "          69,  72, 105,   0,   0,   0,   0],\n",
       "        [  1,   2,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [ 13,  14,  28,  29,  42,  45,  47,  54,  56,  79,  86,  88,  98,\n",
       "         102, 109, 115, 116, 117, 120,   0],\n",
       "        [  2,  14,  17,  23,  26,  28,  29,  43,  47,  57,  66,  68,  79,\n",
       "          82,  91, 101, 120, 122, 126,   0],\n",
       "        [  8,  18,  26,  27,  29,  30,  35,  45,  68,  82,  86,  87,  96,\n",
       "          97,  99, 109, 118, 119, 124,   0],\n",
       "        [  5,   8,  11,  15,  25,  28,  42,  53,  55,  56,  64,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [  6,  17,  19,  24,  27,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [  3,   4,   7,   9,  25,  26,  33,  39,  72,  75,  81,  82,  85,\n",
       "          88,  98, 104, 106, 119, 122,   0],\n",
       "        [  3,   8,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [  2,   7,  10,  16,  20,  31,  43,  46,  54,  66,  67,  68,  76,\n",
       "          89,  96, 101, 112, 115, 118,   0],\n",
       "        [  3,  15,  19,  29,  30,  33,  37,  38,  44,  51,  60,  85,  86,\n",
       "          90,  96,  98,  99, 120, 122,   0],\n",
       "        [ 23,  26,  44,  46,  60,  61,  63,  64,  66,  67,  68,  77,  78,\n",
       "          90, 101, 102,   0,   0,   0,   0],\n",
       "        [  7,   9,  13,  14,  38,  40,  55,  57,  63,  64,  68,  69,  73,\n",
       "          75,  84,  89, 101, 115, 120,   0],\n",
       "        [  7,  11,  22,  23,  25,  32,  47,  61,  63,  65,  73,  78,  96,\n",
       "         100, 109, 118, 119, 123, 125,   0],\n",
       "        [  2,  15,  18,  28,  29,  30,  39,  42,  51,  61,  69,  83,  86,\n",
       "          89,  93,  97, 103, 109, 117,   0],\n",
       "        [  1,   4,   7,  11,  15,  28,  46,  48,  58,  59,  69,  82,  83,\n",
       "          84,  86,  87,  93, 102, 111,   0],\n",
       "        [ 14,  22,  30,  32,  39,  43,  48,  55,  60,  61,  63,  66,  86,\n",
       "          90,  94, 110, 111, 112, 122,   0],\n",
       "        [  3,   6,  19,  24,  28,  43,  45,  57,  61,  64,  68,  71,  75,\n",
       "          96,  98, 106, 113, 120, 122,   0],\n",
       "        [  9,  17,  22,  28,  31,  33,  36,  37,  42,  64,  74,  82, 101,\n",
       "         104, 108, 109, 112, 119, 126,   0],\n",
       "        [  3,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [  3,   5,  13,  15,  20,  23,  37,  39,  40,  43,  56,  86,  88,\n",
       "         101, 105, 106, 108, 112,   0,   0],\n",
       "        [  1,   2,   3,  25,  35,  40,  44,  58,  62,  69,  71,  77,  80,\n",
       "          85, 102, 108, 109, 120, 123,   0],\n",
       "        [  4,  16,  18,  25,  33,  36,  38,  45,  53,  59,  60,  69,  84,\n",
       "          90,   0,   0,   0,   0,   0,   0],\n",
       "        [ 11,  12,  23,  38,  42,  44,  50,  59,  65,  71,  73,  81,  82,\n",
       "          85,   0,   0,   0,   0,   0,   0],\n",
       "        [  5,   6,   8,  14,  28,  34,  35,  38,  41,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0],\n",
       "        [  3,  15,  18,  25,  35,  36,  38,  46,  53,  60,  62,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0]])>,\n",
       " 'masked_lm_weights': <tf.Tensor: shape=(32, 20), dtype=float32, numpy=\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32)>,\n",
       " 'next_sentence_labels': <tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
       " array([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1]])>,\n",
       " 'segment_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, ..., 1, 1, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'input_mask', 'masked_lm_ids', 'masked_lm_positions', 'masked_lm_weights', 'next_sentence_labels', 'segment_ids'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [    2    11     9   561    11     9    37   561     4     9   124  7059\n",
      "   184   561    11     9   346   146    37   561    63    42    18     4\n",
      "    11     9   239    16   962     4     4    38    27     7  1470     4\n",
      "     4   277   469    88     4   190   376  3837     3     6   890     4\n",
      "   812     8  1873     4  2233   596   168   634    22  6660    12     7\n",
      "  2051    58    14     4     4   173    14   105     6   890    48  1964\n",
      "     5    33   493     8    34    18    10   114   238  3736    45     5\n",
      "   104    18    27    11    41 11966  2306     5  1097    17   137     6\n",
      "    92 27167    30     6    25    10  6157    37    10  1081    45     6\n",
      "   849     4    95   191   278 25091   121   423  2481    10   203    80\n",
      "   109     7  3364     8   923    10   924     3]\n",
      "input_mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "masked_lm_ids: [  11  588   44    6   38   24    7    5   48   41 3837  577   60  238\n",
      " 2306   92    8   10    8    0]\n",
      "masked_lm_positions: [  8  23  29  30  31  35  36  40  47  51  60  63  64  80  90  96  97 104\n",
      " 109   0]\n",
      "masked_lm_weights: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "next_sentence_labels: [0]\n",
      "segment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "for k, v in d.items():\n",
    "    print(f\"{k}: {v[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [    2     6    48     4    26  2131    12     3    22     9    71   660\n",
      " 21465    12     3     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "input_mask: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "masked_lm_ids: [ 6 82  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "masked_lm_positions: [1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "masked_lm_weights: [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "next_sentence_labels: [1]\n",
      "segment_ids: [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for k, v in d.items():\n",
    "    print(f\"{k}: {v[31]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"input_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 1, 128), dtype=float32, numpy=\n",
       "array([[[[    -0.,     -0.,     -0., ...,     -0.,     -0.,     -0.]]],\n",
       "\n",
       "\n",
       "       [[[    -0.,     -0.,     -0., ...,     -0.,     -0.,     -0.]]],\n",
       "\n",
       "\n",
       "       [[[    -0.,     -0.,     -0., ...,     -0.,     -0.,     -0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[    -0.,     -0.,     -0., ...,     -0.,     -0.,     -0.]]],\n",
       "\n",
       "\n",
       "       [[[    -0.,     -0.,     -0., ..., -10000., -10000., -10000.]]],\n",
       "\n",
       "\n",
       "       [[[    -0.,     -0.,     -0., ..., -10000., -10000., -10000.]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask = tf.reshape(d[\"input_mask\"], (input_shape[0], 1, 1, input_shape[1]))\n",
    "extended_attention_mask = tf.cast(tf.equal(extended_attention_mask, 0), tf.float32)\n",
    "extended_attention_mask = tf.multiply(extended_attention_mask, tf.constant(-10000.0, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Sub as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9612f2415dc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mone_cst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mten_thousand_cst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10000.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mextended_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_cst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mten_thousand_cst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m   \"\"\"\n\u001b[1;32m--> 561\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  10304\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10305\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10306\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10307\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10308\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute Sub as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Sub]"
     ]
    }
   ],
   "source": [
    "input_shape = d[\"input_mask\"].shape\n",
    "one_cst = tf.constant(1.0, dtype=tf.float32)\n",
    "ten_thousand_cst = tf.constant(-10000.0, dtype=tf.float32)\n",
    "extended_attention_mask = tf.multiply(tf.subtract(one_cst, extended_attention_mask), ten_thousand_cst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1, 1, 128), dtype=int32, numpy=\n",
       "array([[[[1, 1, 1, ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "       [[[1, 1, 1, ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "       [[[1, 1, 1, ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1, 1, 1, ..., 1, 1, 1]]],\n",
       "\n",
       "\n",
       "       [[[1, 1, 1, ..., 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[1, 1, 1, ..., 0, 0, 0]]]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model.embedding' from 'C:\\\\Users\\\\seokjong\\\\dev\\\\MyBert\\\\model\\\\embedding.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import embedding\n",
    "imp.reload(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = embedding.EmbeddingLayer(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 128, 128), dtype=float32, numpy=\n",
       "array([[[-0.48712355, -0.02978358,  0.17945506, ...,  0.8133659 ,\n",
       "         -1.3185583 , -0.34859776],\n",
       "        [-0.38272315, -0.3418512 ,  0.18923788, ..., -0.49261922,\n",
       "         -0.69630814, -0.0270364 ],\n",
       "        [-0.35029596, -0.6971725 ,  0.20470506, ..., -0.08726028,\n",
       "         -1.5033354 ,  0.22702336],\n",
       "        ...,\n",
       "        [-0.18563168, -0.60740757, -0.5342733 , ..., -0.9799013 ,\n",
       "         -1.1144719 ,  0.2728641 ],\n",
       "        [-0.10508169,  0.16639659, -0.87073743, ..., -0.78892237,\n",
       "         -1.112452  ,  0.2574428 ],\n",
       "        [-0.46620467,  0.02814792, -0.04137228, ..., -0.40720013,\n",
       "         -1.4783251 , -0.05667265]],\n",
       "\n",
       "       [[-0.48712355, -0.02978358,  0.17945506, ...,  0.8133659 ,\n",
       "         -1.3185583 , -0.34859776],\n",
       "        [-0.54493445, -0.49895576,  0.05773858, ...,  0.16728738,\n",
       "         -0.65363604, -1.0445409 ],\n",
       "        [-0.16164392, -0.5100623 , -0.21532449, ...,  0.41354927,\n",
       "         -0.5289586 , -0.6852402 ],\n",
       "        ...,\n",
       "        [-1.0725737 , -0.43169567, -0.26465997, ..., -0.78498167,\n",
       "         -1.2554419 ,  0.15829407],\n",
       "        [-0.32482556, -0.14332847, -1.0968134 , ...,  0.14119074,\n",
       "         -0.2691545 ,  0.32172465],\n",
       "        [-0.6707986 , -0.88444495, -0.435068  , ...,  0.2572804 ,\n",
       "         -1.6820163 , -0.8320368 ]],\n",
       "\n",
       "       [[-0.48712355, -0.02978358,  0.17945506, ...,  0.8133659 ,\n",
       "         -1.3185583 , -0.34859776],\n",
       "        [ 0.83909726, -0.10298838,  0.09135261, ..., -0.41771862,\n",
       "          0.29017848,  0.356186  ],\n",
       "        [ 0.21877676, -0.8173398 ,  0.91337115, ..., -0.6123818 ,\n",
       "         -1.14418   , -0.28756043],\n",
       "        ...,\n",
       "        [-0.43848178, -0.64598936, -0.77853775, ..., -1.0062279 ,\n",
       "         -0.7661023 , -0.13108948],\n",
       "        [-0.67130727,  0.20577593, -1.4109055 , ...,  0.34065   ,\n",
       "         -0.73376054,  0.36325163],\n",
       "        [-0.6707986 , -0.88444495, -0.435068  , ...,  0.2572804 ,\n",
       "         -1.6820163 , -0.8320368 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.48712355, -0.02978358,  0.17945506, ...,  0.8133659 ,\n",
       "         -1.3185583 , -0.34859776],\n",
       "        [-0.38272315, -0.3418512 ,  0.18923788, ..., -0.49261922,\n",
       "         -0.69630814, -0.0270364 ],\n",
       "        [ 0.3343776 , -1.1434202 ,  0.17069465, ..., -0.3294916 ,\n",
       "         -0.91117895,  0.06595154],\n",
       "        ...,\n",
       "        [-0.18563168, -0.60740757, -0.5342733 , ..., -0.9799013 ,\n",
       "         -1.1144719 ,  0.2728641 ],\n",
       "        [-0.10508169,  0.16639659, -0.87073743, ..., -0.78892237,\n",
       "         -1.112452  ,  0.2574428 ],\n",
       "        [-0.46620467,  0.02814792, -0.04137228, ..., -0.40720013,\n",
       "         -1.4783251 , -0.05667265]],\n",
       "\n",
       "       [[-0.48712355, -0.02978358,  0.17945506, ...,  0.8133659 ,\n",
       "         -1.3185583 , -0.34859776],\n",
       "        [ 0.83909726, -0.10298838,  0.09135261, ..., -0.41771862,\n",
       "          0.29017848,  0.356186  ],\n",
       "        [ 0.71329314, -0.5008719 ,  0.9054404 , ...,  0.5845208 ,\n",
       "         -1.0103799 ,  0.69707197],\n",
       "        ...,\n",
       "        [-0.56890845, -1.2917482 , -0.29558444, ..., -0.74818563,\n",
       "         -0.8709692 ,  0.00821188],\n",
       "        [-0.06347589, -0.3763398 , -0.5156663 , ..., -1.1175251 ,\n",
       "         -0.88464326,  0.00225704],\n",
       "        [-0.6707986 , -0.88444495, -0.435068  , ...,  0.2572804 ,\n",
       "         -1.6820163 , -0.8320368 ]],\n",
       "\n",
       "       [[-0.48712355, -0.02978358,  0.17945506, ...,  0.8133659 ,\n",
       "         -1.3185583 , -0.34859776],\n",
       "        [ 0.16569893, -1.2088131 , -0.24734038, ...,  0.26527476,\n",
       "         -0.18460417,  0.01623527],\n",
       "        [ 0.6141826 , -0.5869612 ,  0.17024234, ..., -0.70076257,\n",
       "         -1.2248743 ,  0.4264684 ],\n",
       "        ...,\n",
       "        [-1.0725737 , -0.43169567, -0.26465997, ..., -0.78498167,\n",
       "         -1.2554419 ,  0.15829407],\n",
       "        [-0.22359358, -0.46927842, -0.5257836 , ..., -1.0111173 ,\n",
       "         -0.2531883 ,  0.19890529],\n",
       "        [-0.6707986 , -0.88444495, -0.435068  , ...,  0.2572804 ,\n",
       "         -1.6820163 , -0.8320368 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(d['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
       "array([[   2,    5,  684, ...,    0,    0,    0],\n",
       "       [   2, 1191,    9, ...,    5,   86,    3],\n",
       "       [   2,    6,   32, ...,   10,  498,    3],\n",
       "       ...,\n",
       "       [   2,    5,  159, ...,    0,    0,    0],\n",
       "       [   2,    6,    4, ...,  183, 1221,    3],\n",
       "       [   2,   53,  276, ...,    5,   40,    3]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_env]",
   "language": "python",
   "name": "conda-env-tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
